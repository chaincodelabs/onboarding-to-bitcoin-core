= Mempool

== Purpose

. The mempool is designed to hold a list of unconfirmed but valid-according to the current best-chain transactions that the node knows about.
. Transactions will not be added to the mempool if they do not meet fee requirements, are non-standard or double-spend an input of a transaction already in the mempool (excluding BIP 125 RBF transactions).
. Transactions have to pass all policy and validation checks before being allowed to enter the mempool.
. Miners will select transactions from the mempool, along with any other (private) sources they may have, for inclusion into a new block template for mining.

We treat entry into the mempool as acceptance that a transaction would be valid in the next block.

There is also a bitcoin-devwiki page on https://github.com/bitcoin-core/bitcoin-devwiki/wiki/Mempool-and-mining[Mempool and mining^] which includes some additional mempool philosophy.

== Stated mempool policy goals

The documentation subfolder https://github.com/bitcoin/bitcoin/tree/master/doc/policy[doc/policy^] contains up-to-date information on some of the current mempool policy rules.

== Life cycle

=== Initialisation

The primary mempool object itself is initialized onto the node in _init.cpp_ as part of `AppInitMain()` which takes `NodeContext& node` as an argument.

The mempool constructor:

.txmempool.h
[source,cpp,options=nowrap]
----
class CTxMemPool
{
// ...
public:
    /** Create a new CTxMemPool.
     * Sanity checks will be off by default for performance, because otherwise
     * accepting transactions becomes O(N^2) where N is the number of transactions
     * in the pool.
     *
     * @param[in] estimator is used to estimate appropriate transaction fees.
     * @param[in] check_ratio is the ratio used to determine how often sanity checks will run.
     */
    explicit CTxMemPool(CBlockPolicyEstimator* estimator = nullptr, int check_ratio = 0);
// ...
}
----

And the initialisation from _init.cpp_:

.init.cpp#AppInitMain()
[source,cpp,options=nowrap]
----
    assert(!node.mempool);
    int check_ratio = std::min<int>(std::max<int>(args.GetArg("-checkmempool", chainparams.DefaultConsistencyChecks() ? 1 : 0), 0), 1000000);
    node.mempool = std::make_unique<CTxMemPool>(node.fee_estimator.get(), check_ratio);
----

[NOTE]
====
The `check_ratio`, used to determine sanity checks, defaults to 0 for all networks except regtest, unless the `checkmempool` program option has been specified.

Sanity checking here refers to checking the consistency of the entire mempool every time a new transaction has been added, so is computationally expensive to have enabled.
====

==== Loading a previous mempool

If a mempool from a previous program run exists (saved in `mempool.dat`), "Step 11" of `AppInitMain()` in _init.cpp_, "import blocks" calls the following to load the mempool from disk:

.init.cpp#AppInitMain()
[source,cpp,options=nowrap]
----
    chainman.m_load_block = std::thread(&TraceThread<std::function<void()>>, "loadblk", [=, &chainman, &args] {
        ThreadImport(chainman, vImportFiles, args);
    });
----

This is run in its own thread so that (potentially) slow disk I/O has a minimal impact on startup times, and the remainder of startup execution can be continued.

`ThreadImport` actually runs a few jobs sequentially, first it does a reindex (if necessary), followed by loading block files from disk, a check that we are still activated on the best chain according to the blocks we just loaded from disk, and then finally loading the mempool with `chainman.ActiveChainstate().LoadMempool(args);`.

`validation.cpp#LoadMempool()` is pretty much a mirror of `DumpMempool()` described in more detail below in <<Shutdown>>:
First we read the version and count of serialized transactions to follow, then we test each one for expiry before submitting it to <<MemPoolAccept>>, and finally read any remaining `mapDeltas` and `unbroadcast_txids` from the file.

A note that upon loading we test each transaction for expiry before loading to the in-memory mempool model:

.validation.cpp#LoadMempool()
[source,cpp,options=nowrap]
----
    if (nTime > nNow - nExpiryTimeout) {
        LOCK(cs_main);
        assert(std::addressof(::ChainstateActive()) == std::addressof(active_chainstate));
        if (AcceptToMemoryPoolWithTime(chainparams, pool, active_chainstate, tx, nTime, false /* bypass_limits */,
                                       false /* test_accept */).m_result_type == MempoolAcceptResult::ResultType::VALID) {
            ++count;
        } else {
            // mempool may contain the transaction already, e.g. from
            // wallet(s) having loaded it while we were processing
            // mempool transactions; consider these as valid, instead of
            // failed, but mark them as 'already there'
            if (pool.exists(tx->GetHash())) {
                ++already_there;
            } else {
                ++failed;
            }
        }
    } else {
        ++expired;
    }
----

This is related to a default setting not to keep transactions in the mempool longer than 336 hours, i.e. two weeks.
The default value comes from the constant `DEFAULT_MEMPOOL_EXPIRE` which can be overridden by the user with the `-mempoolexpiry` option.
Loading (and validating) a mempool of transactions this old is likely a waste of time and resources.

____
  -mempoolexpiry=<n>
       Do not keep transactions in the mempool longer than <n> hours (default: 336)
____

=== Runtime execution

While the node is running the mempool is persisted in memory.
By default the mempool is limited to 300MB as specified by `DEFAULT_MAX_MEMPOOL_SIZE`.
This can be overridden by the program option `maxmempoolsize`.

See <<Transaction format in the mempool>> for more information on what data counts towards this limit, or review the `CTxMemPool` data members which store current usage metrics e.g. `CTxMemPool::cachedInnerUsage` and the implementation of e.g. `CTxMemPool::DynamicMemoryUsage()`.

=== Shutdown

When the node is shut down its mempool is (by default) persisted to disk called from `init.cpp#Shutdown()`:

.init.cpp#Shutdown()
[source,cpp,options=nowrap]
----
    if (node.mempool && node.mempool->IsLoaded() && node.args->GetArg("-persistmempool", DEFAULT_PERSIST_MEMPOOL)) {
        DumpMempool(*node.mempool);
    }
----

A pointer to the mempool object is passed to `DumpMempool()`, which begins by locking the mempool mutex, `pool.cs`, before creating a duplicate of its `mapDeltas` member.
// TODO: Why is this duplicated?
`mapDeltas` is used by miners to apply (fee) prioritisation to certain transactions when creating new block templates.
Information on each transaction is stored in a vector of `CTxMempoolInfo` objects called `vinfo`.

.validation.cpp#DumpMempool()
[source,cpp,options=nowrap]
----
bool DumpMempool(const CTxMemPool& pool, FopenFn mockable_fopen_function, bool skip_file_commit)
{
    int64_t start = GetTimeMicros();

    std::map<uint256, CAmount> mapDeltas;
    std::vector<TxMempoolInfo> vinfo;
    std::set<uint256> unbroadcast_txids;

    static Mutex dump_mutex;
    LOCK(dump_mutex);

    {
        LOCK(pool.cs);
        for (const auto &i : pool.mapDeltas) {
            mapDeltas[i.first] = i.second;
        }
        vinfo = pool.infoAll();
        unbroadcast_txids = pool.GetUnbroadcastTxs();
    }
----

Next a new (temporary) file is opened and some metadata related to mempool version and size is written to the front.
Afterwards we loop through `vinfo` writing the transaction, the time it entered the mempool and the fee delta (prioritisation) to the file, before deleting its entry from our `mapDeltas` mirror.

Finally, any transactions remaining in `mapDeltas`, which is now effectively the set of unbroadcasted transactions, are appended to the file.

.validation.cpp#DumpMempool()
[source,cpp,options=nowrap]
----
    // ...
    try {
        FILE* filestr{mockable_fopen_function(GetDataDir() / "mempool.dat.new", "wb")};
        if (!filestr) {
            return false;
        }

        CAutoFile file(filestr, SER_DISK, CLIENT_VERSION);

        uint64_t version = MEMPOOL_DUMP_VERSION;
        file << version;

        file << (uint64_t)vinfo.size();
        for (const auto& i : vinfo) {
            file << *(i.tx);
            file << int64_t{count_seconds(i.m_time)};
            file << int64_t{i.nFeeDelta};
            mapDeltas.erase(i.tx->GetHash());
        }

        file << mapDeltas;

        LogPrintf("Writing %d unbroadcast transactions to disk.\n", unbroadcast_txids.size());
        file << unbroadcast_txids;
    // ...
}
----

****
We are able to write (and later read) `mapDeltas` to the file only using the `<<` operator.
This is due to the operator overload on the `CAutoFile` class found in _streams.h_:

.streams.h
[source,cpp,options=nowrap]
----
/**
 * map
 */
template<typename Stream, typename K, typename T, typename Pred, typename A>
void Serialize(Stream& os, const std::map<K, T, Pred, A>& m)
{
    WriteCompactSize(os, m.size());
    for (const auto& entry : m)
        Serialize(os, entry);
}

class: CAutoFile
{
public:
    // ...
    template<typename T>
    CAutoFile& operator<<(const T& obj)
    {
        // Serialize to this stream
        if (!file)
            throw std::ios_base::failure("CAutoFile::operator<<: file handle is nullptr");
        ::Serialize(*this, obj);
        return (*this);
    }
    // ...
};
----

The same is true for serialisation of `std::set<uint256> unbroadcast_txids;` later in the function.

****

Finally, if writing the elements to the temporary file was successful, we close the file and rename it to `mempool.dat`.

== Mapping transactions in the mempool

A lot of the mempool magic -- how fee-efficient block templates can be swiftly generated from chains of potentially-complex transactions -- comes down to ``CTxMempool``'s special `boost::multi_index` `maptx` which is able to natively store transactions in an index against multiple criteria, as described in the https://www.boost.org/doc/libs/1_68_0/libs/multi_index/doc/index.html[documentation^] and code comments:

.txmempool.h#CTxMempool
[source,cpp,options=nowrap]
----

/*
 * mapTx is a boost::multi_index that sorts the mempool on 5 criteria:
 * - transaction hash (txid)
 * - witness-transaction hash (wtxid)
 * - descendant feerate [we use max(feerate of tx, feerate of tx with all descendants)]
 * - time in mempool
 * - ancestor feerate [we use min(feerate of tx, feerate of tx with all unconfirmed ancestors)]
 */

 // ...

    typedef boost::multi_index_container<
        CTxMemPoolEntry,
        boost::multi_index::indexed_by<
            // sorted by txid
            boost::multi_index::hashed_unique<mempoolentry_txid, SaltedTxidHasher>,
            // sorted by wtxid
            boost::multi_index::hashed_unique<
                boost::multi_index::tag<index_by_wtxid>,
                mempoolentry_wtxid,
                SaltedTxidHasher
            >,
            // sorted by fee rate
            boost::multi_index::ordered_non_unique<
                boost::multi_index::tag<descendant_score>,
                boost::multi_index::identity<CTxMemPoolEntry>,
                CompareTxMemPoolEntryByDescendantScore
            >,
            // sorted by entry time
            boost::multi_index::ordered_non_unique<
                boost::multi_index::tag<entry_time>,
                boost::multi_index::identity<CTxMemPoolEntry>,
                CompareTxMemPoolEntryByEntryTime
            >,
            // sorted by fee rate with ancestors
            boost::multi_index::ordered_non_unique<
                boost::multi_index::tag<ancestor_score>,
                boost::multi_index::identity<CTxMemPoolEntry>,
                CompareTxMemPoolEntryByAncestorFee
            >
        >
    > indexed_transaction_set;
    //...
    mutable RecursiveMutex cs;
    indexed_transaction_set mapTx GUARDED_BY(cs);
----

We can see here the 5 sort fields including tags on `index_by_wtxid`, `descendant_score`, `entry_time` and `ancestor_score`.

`index_by_wtxid` is used when checking whether transactions received over the P2P network already exist in the mempool (via the `exists()` function).

`descendant_score` is used when we are trying to trim the mempool to size (via `TrimToSize()`).
In this case we want to keep parent (ancestor) transactions in the mempool who have high fee-paying children (descendants).

`entry_time` is used to calculate when transactions in the mempool should expire.
Again this is based on the value of `DEFAULT_MEMPOOL_EXPIRE` as with <<Loading a previous mempool>>.

`ancestor_score` is the most-used tagged index.
This is because `ancestor_score`, or in other words the fee:weight ratio of a package of transactions, is used from within the mining code (`BlockAssembler`) to create new block templates.
From the docs:

.miner.cpp#BlockAssembler::addPackageTxs()
[source,cpp,options=nowrap]
----
// This transaction selection algorithm orders the mempool based
// on feerate of a transaction including all unconfirmed ancestors.
// ...
----

Finally the default, and untagged, sort field of the index, which is using the https://www.boost.org/doc/libs/1_62_0/libs/multi_index/doc/reference/hash_indices.html#unique_non_unique[hashed_unique^] sort, hashing the transaction ID using Bitcoin Core's implementation of the SipHash hasher for TXIDs:

.util/hasher.h
[source,cpp,options=nowrap]
----
class SaltedTxidHasher
{
private:
    /** Salt */
    const uint64_t k0, k1;

public:
    SaltedTxidHasher();

    size_t operator()(const uint256& txid) const {
        return SipHashUint256(k0, k1, txid);
    }
};
----

The default index is used in most places that `mapTx` is found.
This includes adding and removing transactions from the mempool, requesting and looking up mempool transactions (by txid) and checking whether RBF is enabled to list a few.

== Transaction format in the mempool

``CTXMemPoolEntry``s describe mempool entries (i.e. transactions) in the mempool.
They store not only transaction information, but also pre-computed information about ancestors.

.txmempool.h
[source,cpp,options=nowrap]
----

class CTxMemPoolEntry
{
public:
    typedef std::reference_wrapper<const CTxMemPoolEntry> CTxMemPoolEntryRef;
    // two aliases, should the types ever diverge
    typedef std::set<CTxMemPoolEntryRef, CompareIteratorByHash> Parents;
    typedef std::set<CTxMemPoolEntryRef, CompareIteratorByHash> Children;

private:
    const CTransactionRef tx;
    mutable Parents m_parents;
    mutable Children m_children;
    const CAmount nFee;             //!< Cached to avoid expensive parent-transaction lookups
    const size_t nTxWeight;         //!< ... and avoid recomputing tx weight (also used for GetTxSize())
    const size_t nUsageSize;        //!< ... and total memory usage
    const int64_t nTime;            //!< Local time when entering the mempool
    const unsigned int entryHeight; //!< Chain height when entering the mempool
    const bool spendsCoinbase;      //!< keep track of transactions that spend a coinbase
    const int64_t sigOpCost;        //!< Total sigop cost
    int64_t feeDelta;          //!< Used for determining the priority of the transaction for mining in a block
    LockPoints lockPoints;     //!< Track the height and time at which tx was final

    // Information about descendants of this transaction that are in the
    // mempool; if we remove this transaction we must remove all of these
    // descendants as well.
    uint64_t nCountWithDescendants;  //!< number of descendant transactions
    uint64_t nSizeWithDescendants;   //!< ... and size
    CAmount nModFeesWithDescendants; //!< ... and total fees (all including us)

    // Analogous statistics for ancestor transactions
    uint64_t nCountWithAncestors;
    uint64_t nSizeWithAncestors;
    CAmount nModFeesWithAncestors;
    int64_t nSigOpCostWithAncestors;

    // ...
----

The advantage to having pre-computed data on descendants and ancestors stored with each transaction in the mempool is that operations involving adding and removing transactions can be performed faster.
When we add a transaction to the mempool we must update the descendant data for all ancestor ``CTxMemPoolEntry``'s.
Conversely if we remove a transaction from the mempool, we must also remove all of its descendants.
A particular area where speed can be critical is in block assembly.

Some of this extra transaction metadata however *does* count towards the mempool's maximum size, therefore a default mempool of 300MB will contain less than 300MB of serialized transactions.

== Adding transactions to the mempool

Transactions can be added to the mempool in four ways:

. Received in a `TX` network message

. From a transaction generated by the wallet or submitted through another interface like RPC.

. Loaded from mempool.dat

. From a disconnected block during a reorg


In all cases, the transaction is submitted to the mempool through AcceptToMemoryPool (ATMP).
For a transaction received over the P2P protocol, the call to ATMP is found in _net_processing.cpp_:

.net_processing.cpp
[source,cpp,options=nowrap]
----
    // ...

    if (msg_type == NetMsgType::TX) {

    // ...

        const MempoolAcceptResult result = AcceptToMemoryPool(m_chainman.ActiveChainstate(), m_mempool, ptx, false /* bypass_limits */);
        const TxValidationState& state = result.m_state;

        if (result.m_result_type == MempoolAcceptResult::ResultType::VALID) {
            m_mempool.check(m_chainman.ActiveChainstate());
            // As this version of the transaction was acceptable, we can forget about any
            // requests for it.
            m_txrequest.ForgetTxHash(tx.GetHash());
            m_txrequest.ForgetTxHash(tx.GetWitnessHash());
            RelayTransaction(tx.GetHash(), tx.GetWitnessHash());
            m_orphanage.AddChildrenToWorkSet(tx, peer->m_orphan_work_set);

            pfrom.nLastTXTime = GetTime();

            LogPrint(BCLog::MEMPOOL, "AcceptToMemoryPool: peer=%d: accepted %s (poolsz %u txn, %u kB)\n",
                pfrom.GetId(),
                tx.GetHash().ToString(),
                m_mempool.size(), m_mempool.DynamicMemoryUsage() / 1000);

            for (const CTransactionRef& removedTx : result.m_replaced_transactions.value()) {
                AddToCompactExtraTransactions(removedTx);
            }

            // Recursively process any orphan transactions that depended on this one
            ProcessOrphanTx(peer->m_orphan_work_set);
        }

        // ...

----

...whereas for locally-generated transactions the call to ATMP comes from `node/transaction.cpp::BroadcastTransaction()`, which is called from the `sendrawtransaction` RPC and from various wallet functions.
We can see this in the call-graph for `AcceptToMemoryPool`:

image::validation_8h_af6c5c758554417ece7c885200c9a6d03_icgraph.svg[]

NOTE: `while` in the diagram stems from the `ThreadMessageHandler()` loop.

== MemPoolAccept

The `MemPoolAccept` class handles mempool validation for new transactions.

Selecting the best transactions for the resource-constrained mempool involves a trade-off between optimistically validating candidates to identify the highest feerate ones and protecting the node from DoS attacks.
As such, we apply a set of validation rules known as mempool _policy_ in addition to consensus.

We might categorize transaction validation checks in a few different ways:

* Consensus vs Policy: These can also be thought of as mandatory vs non-mandatory checks.
These two are not mutually exclusive, but we make efforts to compartmentalize consensus rules.
* Script vs Non-script: Script refers to the instructions and data used to specify and satisfy spending conditions.
We make this distinction because script checking (specifically, signature verification) is the most computationally intensive part of transaction validation.
* Contextual vs Context-Free: The context refers to our knowledge of the current state, represented as https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/validation.h#L566[ChainState^].
Contextual checks might require the current block height or knowledge of the current UTXO set, while context-free checks only need the transaction itself.
We also need to look into our mempool to validate a transaction that spends unconfirmed parents or conflicts with another transaction already in our mempool.

=== Context-free non-script checks

Mempool validation in Bitcoin Core starts off with non-script checks (sometimes called https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/validation.cpp#L541["PreChecks"^], the name of the function in which these checks run).

As a defensive strategy the node starts with context-free and/or easily computed checks.
Here are some examples:

* None of the outputs are trying to send a value https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/consensus/tx_check.cpp#L25-L27[less than 0 or greater than 21 million
  BTC^].
* The transaction https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/validation.cpp#L568[isn't a coinbase^], as there can't be any coinbase transactions outside of blocks.
* The transaction isn't https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/policy/policy.cpp#L88[more than 400,000 weight units^].
+
It's possible for a larger transaction to be consensus-valid, but it would occupy too much space in the mempool.
If we allowed these transactions an attacker could try to dominate our mempool with very large transactions that are never mined.

=== Contextual non-script checks

Perhaps the most obvious non-script contextual check here is to https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/validation.cpp#L641-L662[make sure the inputs are available^], either in the current chainstate or an unspent output of an in-mempool transaction.
Instead of looking through the entire blockchain (hundreds of gigabytes stored on disk), Bitcoin Core nodes keep a https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/validation.h#L517-L541[layered cache^] of the available https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/coins.h#L30[coins^] (a few gigabytes, much of which can be kept in memory).
To make this process more efficient, coins fetched from disk during mempool validation are https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/validation.cpp#L1116-L1124[kept in memory^] if the transaction is accepted to the mempool.

Timelocks are also checked here - the node grabs the BIP113 Median Time Past and/or block height at the current chainstate to check transaction `nLockTime` and input `nSequence`

=== "Contextual" Script Checks

Transaction https://doxygen.bitcoincore.org/validation_8cpp.html#a6a96a3e1e6818904fdd5f51553b7ea60[script checks^] are actually context-free in isolation; the https://doxygen.bitcoincore.org/class_c_tx_in.html#aba540fd902366210a6ad6cd9a18fe763[`scriptSig`^] and https://github.com/bitcoin/bips/blob/master/bip-0141.mediawiki#specification[`witness`^] for each input, paired with the https://doxygen.bitcoincore.org/class_c_tx_out.html#a25bf3f2f4befb22a6a0be45784fe57e2[`scriptPubKey`^] in the https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/validation.cpp#L1469[corresponding UTXO^] can be passed into the script interpreter and validated without state.
The https://doxygen.bitcoincore.org/interpreter_8h.html[script interpreter^] simply evaluates the series of opcodes and data based on the arguments passed to it.

The "context" passed to the script interpreter is a set of https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/script/interpreter.h#L42-L143[script verification flags^] indicating which rules to apply during script verification.
For example, the `OP_CHECKSEQUENCEVERIFY` opcode repurposed `OP_NOP3`.
The script verification flag `SCRIPT_VERIFY_CHECKSEQUENCEVERIFY` instructs the script interpreter https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/script/interpreter.cpp#L587[to interpret^] the opcode `0xb2` as the instruction to check that the input's `nSequence` is greater than the stack value or as a no-op. Starting at the BIP112 activation height, https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/validation.cpp#L1695-L1697[nodes pass^] `SCRIPT_VERIFY_CHECKSEQUENCEVERIFY=1` into the script interpreter during consensus script checks.

=== Context-free Signature and Script Checks

Mempool validation performs two sets of script checks: https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/validation.cpp#L917[`PolicyScriptChecks`^] and https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/validation.cpp#L943[`ConsensusScriptChecks`^].
The former runs the script interpreter using consensus and policy flags and caches the signature result (if successful) in the https://github.com/bitcoin/bitcoin/blob/d67330d11245b11fbdd5e2dd5343ee451186931e/src/script/sigcache.cpp#L21-L26[signature cache^].
The latter runs the script interpreter using https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/validation.cpp#L965[consensus flags only^] and caches the full validation result in the script execution cache, identified by the wtxid and script verification flags.
If a new consensus rule is activated between now and the block in which this transaction is included, the cached result is no longer valid, but this is easily detected based on the script verification flags.

For example, before taproot rules are enforced in consensus, they are in policy (`SCRIPT_VERIFY_TAPROOT` included in policy but not consensus script verification flags); nodes won't relay and accept taproot-invalid version 1 transactions into their mempools, even though they aren't breaking any consensus rules yet.
All script checks will be cached without `SCRIPT_VERIFY_TAPROOT`.
After taproot activation, if a previously-validated transaction is seen, the cache entry's script verification flags won't match current consensus flags, so the node will re-run script checks for that transaction.

The most computationally-intensive part of script validation is signature verification (indicated in a script by opcodes such as `OP_CHECKSIG`), which doesn't change based on context.
To save the node from repetitive work, at the very start of script checks, parts of the transaction are https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/script/interpreter.cpp#L1423[serialized, hashed, and stored^] in a `PrecomputedTransactionData` struct for use in signature verification.
This is especially handy in transactions that have multiple inputs and/or signatures.
Additionally, the cached result from `PolicyScriptChecks` can be used immediately in `ConsensusScriptChecks`; we almost never need to verify the same signature more than once!

== Submission to Mempool

Every entry in the mempool contains a transaction, and various metadata such as the time it was received, its fees (for faster lookup), the height and/or time needed to satisfy its timelocks, and pointers to any parents and children in the mempool.

Much of the mempool is devoted to keeping track of a transaction's in-mempool ancestors (parents, parents of parents, etc.) and descendants (children, children of children, etc.) and their aggregated fees.
A transaction is only valid if its ancestors exist: a transaction can't be mined unless its parents are mined, and its parents can't be mined unless their parents are mined, and so on.
Conversely, if a transaction is evicted from the mempool, its descendants must be too.

As such, a transaction's effective feerate is not just its base feerate divided by weight, but that of itself and all of its ancestors.
This information is also taken into account when the mempool fills up and the node must choose which transactions to evict (also based on fees).
Of course, all of this information can be calculated on the fly, but constructing a block is extremely time-sensitive, so the mempool opts to cache this information rather than spend more time calculating it.
As one might imagine, the family DAGs can get quite hairy and a source of resource exhaustion, so one part of mempool policy is to limit individual transactions' connectivity.

== Package relay

https://bitcoinops.org/en/topics/package-relay/[Package Relay^] is a long-discussed concept and, at the time of writing, is a work in progress in Bitcoin Core.
A significant portion of the project involves changes to mempool validation, which glozow describes in her gist https://gist.github.com/glozow/dc4e9d5c5b14ade7cdfac40f43adb18a[Package mempool accept^].

https://github.com/bitcoin/bitcoin/pull/20833[PR#20833^] added the ability for mempool validation to assess a set of dependent transactions and enabled the `testmempoolaccept` RPC to support multiple transactions.

https://github.com/bitcoin/bitcoin/pull/21800[PR#21800^] added the ability to analyse and limit the ancestor and descendant sets of packages in relation to the mempool.

https://github.com/bitcoin/bitcoin/pull/22674[PR#22674^] defined child-with-unconfirmed-parents packages and enabled submission of such packages to the mempool.

These PRs were also preceded by several refactoring efforts:
https://github.com/bitcoin/bitcoin/pull/21062[PR#21062^],
https://github.com/bitcoin/bitcoin/pull/22796[PR#22796^],
https://github.com/bitcoin/bitcoin/pull/22675[PR#22675^],
https://github.com/bitcoin/bitcoin/pull/22855[PR#22855^],
https://github.com/bitcoin/bitcoin/pull/23381[PR#23381^].

The document https://github.com/bitcoin/bitcoin/blob/master/doc/policy/packages.md[doc/policy/packages.md^] contains current information on the stated package acceptance rules.

