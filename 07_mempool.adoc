= Mempool

== Purpose

. The mempool is designed to hold a list of unconfirmed but valid-according to the current best-chain transactions that the node knows about.
. Transactions will not be added to the mempool if they do not meet fee requirements, are non-standard or double-spend an input of a transaction already in the mempool (excluding BIP 125 RBF transactions).
. Transactions have to pass all policy and validation checks before being allowed to enter the mempool.
. Miners will select transactions from the mempool, along with any other (private) sources they may have, for inclusion into a new block template for mining.

We treat entry into the mempool as acceptance that a transaction would be valid in the next block.

There is also a bitcoin-devwiki page on https://github.com/bitcoin-core/bitcoin-devwiki/wiki/Mempool-and-mining[Mempool and mining] which includes some additional mempool philosophy.

== Stated mempool policy goals

The documentation subfolder https://github.com/bitcoin/bitcoin/tree/master/doc/policy[doc/policy] contains up-to-date information on some of the current mempool policy rules.

== Life cycle

=== Initialisation

The primary mempool object itself is initialised onto the node in _init.cpp_ as part of `AppInitMain()` which takes `NodeContext& node` as an argument.

The mempool constructor:

.txmempool.h
[source, cpp]
----
class CTxMemPool
{
// ...
public:
    /** Create a new CTxMemPool.
     * Sanity checks will be off by default for performance, because otherwise
     * accepting transactions becomes O(N^2) where N is the number of transactions
     * in the pool.
     *
     * @param[in] estimator is used to estimate appropriate transaction fees.
     * @param[in] check_ratio is the ratio used to determine how often sanity checks will run.
     */
    explicit CTxMemPool(CBlockPolicyEstimator* estimator = nullptr, int check_ratio = 0);
// ...
}
----

And the initialisation from _init.cpp_:

.init.cpp#AppInitMain()
[source,cpp]
----
    assert(!node.mempool);
    int check_ratio = std::min<int>(std::max<int>(args.GetArg("-checkmempool", chainparams.DefaultConsistencyChecks() ? 1 : 0), 0), 1000000);
    node.mempool = std::make_unique<CTxMemPool>(node.fee_estimator.get(), check_ratio);
----

[NOTE]
====
The `check_ratio`, used to determine sanity checks, defaults to 0 for all networks except regtest, unless the `checkmempool` program option has been specified.

Sanity checking here refers to checking the consistency of the entire mempool every time a new transaction has been added, so is computationally expensive to have enabled.
====

==== Loading a previous mempool

If a mempool from a previous program run exists (saved in `mempool.dat`), "Step 11" of `AppInitMain()` in _init.cpp_, "import blocks" calls the following to load the mempool from disk:

.init.cpp#AppInitMain()
[source,cpp]
----
    chainman.m_load_block = std::thread(&TraceThread<std::function<void()>>, "loadblk", [=, &chainman, &args] {
        ThreadImport(chainman, vImportFiles, args);
    });
----

This is run in its own thread so that (potentially) slow disk I/O has a minimal impact on startup times, and the remainder of startup execution can be continued.

`ThreadImport` actually runs a few jobs sequentially, first it does a reindex (if necessary), followed by loading block files from disk, a check that we are still activated on the best chain according to the blocks we just loaded from disk, and then finally loading the mempool with `chainman.ActiveChainstate().LoadMempool(args);`.

`validation.cpp#LoadMempool()` is pretty much a mirror of `DumpMempool()` described in more detail below in <<Shutdown>>:
First we read the version and count of serialised transactions to follow, then we test each one for expiry before submitting it to <<AcceptToMemoryPool>>, and finally read any remaining `mapDeltas` and `unbroadcast_txids` from the file.

A note that upon loading we test each transaction for expiry before loading to the in-memory mempool model:

.validation.cpp#LoadMempool()
[source,cpp]
----
    if (nTime > nNow - nExpiryTimeout) {
        LOCK(cs_main);
        assert(std::addressof(::ChainstateActive()) == std::addressof(active_chainstate));
        if (AcceptToMemoryPoolWithTime(chainparams, pool, active_chainstate, tx, nTime, false /* bypass_limits */,
                                       false /* test_accept */).m_result_type == MempoolAcceptResult::ResultType::VALID) {
            ++count;
        } else {
            // mempool may contain the transaction already, e.g. from
            // wallet(s) having loaded it while we were processing
            // mempool transactions; consider these as valid, instead of
            // failed, but mark them as 'already there'
            if (pool.exists(tx->GetHash())) {
                ++already_there;
            } else {
                ++failed;
            }
        }
    } else {
        ++expired;
    }
----

This is related to a default setting not to keep transactions in the mempool longer than 336 hours, i.e. two weeks.
The default value comes from the constant `DEFAULT_MEMPOOL_EXPIRE` which can be overridden by the user with the `-mempoolexpiry` option.
Loading (and validating) a mempool of transactions this old is likely a waste of time and resources.

____
  -mempoolexpiry=<n>
       Do not keep transactions in the mempool longer than <n> hours (default: 336)
____

=== Runtime execution

While the node is running the mempool is persisted in memory.
By default the mempool is limited to 300MB as specified by `DEFAULT_MAX_MEMPOOL_SIZE`.
This can be overridden by the program option `maxmempoolsize`.

See <<Transaction format in the mempool>> for more information on what data counts towards this limit, or review the `CTxMemPool` data members which store current usage metrics e.g. `CTxMemPool::cachedInnerUsage` and the implementation of e.g. `CTxMemPool::DynamicMemoryUsage()`.

=== Shutdown

When the node is shut down its mempool is (by default) persisted to disk called from `init.cpp#Shutdown()`:

.init.cpp#Shutdown()
[source,cpp]
----
    if (node.mempool && node.mempool->IsLoaded() && node.args->GetArg("-persistmempool", DEFAULT_PERSIST_MEMPOOL)) {
        DumpMempool(*node.mempool);
    }
----

A pointer to the mempool object is passed to `DumpMempool()`, which begins by locking the mempool mutex, `pool.cs`, before creating a duplicate of its `mapDeltas` member.
// TODO: Why is this duplicated?
`mapDeltas` is used by miners to apply (fee) prioritisation to certain transactions when creating new block templates.
Information on each transaction is stored in a vector of `CTxMempoolInfo` objects called `vinfo`.

.validation.cpp#DumpMempool()
[source,cpp]
----
bool DumpMempool(const CTxMemPool& pool, FopenFn mockable_fopen_function, bool skip_file_commit)
{
    int64_t start = GetTimeMicros();

    std::map<uint256, CAmount> mapDeltas;
    std::vector<TxMempoolInfo> vinfo;
    std::set<uint256> unbroadcast_txids;

    static Mutex dump_mutex;
    LOCK(dump_mutex);

    {
        LOCK(pool.cs);
        for (const auto &i : pool.mapDeltas) {
            mapDeltas[i.first] = i.second;
        }
        vinfo = pool.infoAll();
        unbroadcast_txids = pool.GetUnbroadcastTxs();
    }
----

Next a new (temporary) file is opened and some metadata related to mempool version and size is written to the front.
Afterwards we loop through `vinfo` writing the transaction, the time it entered the mempool and the fee delta (prioritisation) to the file, before deleting its entry from our `mapDeltas` mirror.

Finally, any transactions remaining in `mapDeltas`, which is now effectively the set of unbroadcasted transactions, are appended to the file.

.validation.cpp#DumpMempool()
[source,cpp]
----
    // ...
    try {
        FILE* filestr{mockable_fopen_function(GetDataDir() / "mempool.dat.new", "wb")};
        if (!filestr) {
            return false;
        }

        CAutoFile file(filestr, SER_DISK, CLIENT_VERSION);

        uint64_t version = MEMPOOL_DUMP_VERSION;
        file << version;

        file << (uint64_t)vinfo.size();
        for (const auto& i : vinfo) {
            file << *(i.tx);
            file << int64_t{count_seconds(i.m_time)};
            file << int64_t{i.nFeeDelta};
            mapDeltas.erase(i.tx->GetHash());
        }

        file << mapDeltas;

        LogPrintf("Writing %d unbroadcast transactions to disk.\n", unbroadcast_txids.size());
        file << unbroadcast_txids;
    // ...
}
----

****
We are able to write (and later read) `mapDeltas` to the file only using the `<<` operator.
This is due to the operator overload on the `CAutoFile` class found in _streams.h_:

.streams.h
[source,cpp]
----
/**
 * map
 */
template<typename Stream, typename K, typename T, typename Pred, typename A>
void Serialize(Stream& os, const std::map<K, T, Pred, A>& m)
{
    WriteCompactSize(os, m.size());
    for (const auto& entry : m)
        Serialize(os, entry);
}

class: CAutoFile
{
public:
    // ...
    template<typename T>
    CAutoFile& operator<<(const T& obj)
    {
        // Serialize to this stream
        if (!file)
            throw std::ios_base::failure("CAutoFile::operator<<: file handle is nullptr");
        ::Serialize(*this, obj);
        return (*this);
    }
    // ...
};
----

The same is true for serialisation of `std::set<uint256> unbroadcast_txids;` later in the function.

****

Finally, if writing the elements to the temporary file was successful, we close the file and rename it to `mempool.dat`.

== Mapping transactions in the mempool

A lot of the mempool magic -- how fee-efficient block templates can be swiftly generated from chains of potentially-complex transactions -- comes down to ``CTxMempool``'s special `boost::multi_index` `maptx` which is able to natively store transactions in an index against multiple criteria, as described in the https://www.boost.org/doc/libs/1_68_0/libs/multi_index/doc/index.html[documentation] and code comments:

.txmempool.h#CTxMempool
[source, cpp]
----

/*
 * mapTx is a boost::multi_index that sorts the mempool on 5 criteria:
 * - transaction hash (txid)
 * - witness-transaction hash (wtxid)
 * - descendant feerate [we use max(feerate of tx, feerate of tx with all descendants)]
 * - time in mempool
 * - ancestor feerate [we use min(feerate of tx, feerate of tx with all unconfirmed ancestors)]
 */

 // ...

    typedef boost::multi_index_container<
        CTxMemPoolEntry,
        boost::multi_index::indexed_by<
            // sorted by txid
            boost::multi_index::hashed_unique<mempoolentry_txid, SaltedTxidHasher>,
            // sorted by wtxid
            boost::multi_index::hashed_unique<
                boost::multi_index::tag<index_by_wtxid>,
                mempoolentry_wtxid,
                SaltedTxidHasher
            >,
            // sorted by fee rate
            boost::multi_index::ordered_non_unique<
                boost::multi_index::tag<descendant_score>,
                boost::multi_index::identity<CTxMemPoolEntry>,
                CompareTxMemPoolEntryByDescendantScore
            >,
            // sorted by entry time
            boost::multi_index::ordered_non_unique<
                boost::multi_index::tag<entry_time>,
                boost::multi_index::identity<CTxMemPoolEntry>,
                CompareTxMemPoolEntryByEntryTime
            >,
            // sorted by fee rate with ancestors
            boost::multi_index::ordered_non_unique<
                boost::multi_index::tag<ancestor_score>,
                boost::multi_index::identity<CTxMemPoolEntry>,
                CompareTxMemPoolEntryByAncestorFee
            >
        >
    > indexed_transaction_set;
    //...
    mutable RecursiveMutex cs;
    indexed_transaction_set mapTx GUARDED_BY(cs);
----

We can see here the 5 sort fields including tags on `index_by_wtxid`, `descendant_score`, `entry_time` and `ancestor_score`.

`index_by_wtxid` is used when checking whether transactions received over the P2P network already exist in the mempool (via the `exists()` function).

`descendant_score` is used when we are trying to trim the mempool to size (via `TrimToSize()`).
In this case we want to keep parent (ancestor) transactions in the mempool who have high fee-paying children (descendants).

`entry_time` is used to calculate when transactions in the mempool should expire.
Again this is based on the value of `DEFAULT_MEMPOOL_EXPIRE` as with <<Loading a previous mempool>>.

`ancestor_score` is the most-used tagged index.
This is because `ancestor_score`, or in other words the fee:weight ratio of a package of transactions, is used from within the mining code (`BlockAssembler`) to create new block templates.
From the docs:

.miner.cpp#BlockAssembler::addPackageTxs()
[source,cpp]
----
// This transaction selection algorithm orders the mempool based
// on feerate of a transaction including all unconfirmed ancestors.
// ...
----

Finally the default, and untagged, sort field of the index, which is using the https://www.boost.org/doc/libs/1_62_0/libs/multi_index/doc/reference/hash_indices.html#unique_non_unique[hashed_unique] sort, hashing the transaction ID using Bitcoin Core's implementation of the SipHash hasher for TXIDs:

.util/hasher.h
[source,cpp]
----
class SaltedTxidHasher
{
private:
    /** Salt */
    const uint64_t k0, k1;

public:
    SaltedTxidHasher();

    size_t operator()(const uint256& txid) const {
        return SipHashUint256(k0, k1, txid);
    }
};
----

The default index is used in most places that `mapTx` is found.
This includes adding and removing transactions from the mempool, requesting and looking up mempool transactions (by txid) and checking whether RBF is enabled to list a few.

== Transaction format in the mempool

``CTXMemPoolEntry``s describe mempool entries (i.e. transactions) in the mempool.
They store not only transaction information, but also pre-computed information about ancestors.

.txmempool.h
[source,cpp]
----

class CTxMemPoolEntry
{
public:
    typedef std::reference_wrapper<const CTxMemPoolEntry> CTxMemPoolEntryRef;
    // two aliases, should the types ever diverge
    typedef std::set<CTxMemPoolEntryRef, CompareIteratorByHash> Parents;
    typedef std::set<CTxMemPoolEntryRef, CompareIteratorByHash> Children;

private:
    const CTransactionRef tx;
    mutable Parents m_parents;
    mutable Children m_children;
    const CAmount nFee;             //!< Cached to avoid expensive parent-transaction lookups
    const size_t nTxWeight;         //!< ... and avoid recomputing tx weight (also used for GetTxSize())
    const size_t nUsageSize;        //!< ... and total memory usage
    const int64_t nTime;            //!< Local time when entering the mempool
    const unsigned int entryHeight; //!< Chain height when entering the mempool
    const bool spendsCoinbase;      //!< keep track of transactions that spend a coinbase
    const int64_t sigOpCost;        //!< Total sigop cost
    int64_t feeDelta;          //!< Used for determining the priority of the transaction for mining in a block
    LockPoints lockPoints;     //!< Track the height and time at which tx was final

    // Information about descendants of this transaction that are in the
    // mempool; if we remove this transaction we must remove all of these
    // descendants as well.
    uint64_t nCountWithDescendants;  //!< number of descendant transactions
    uint64_t nSizeWithDescendants;   //!< ... and size
    CAmount nModFeesWithDescendants; //!< ... and total fees (all including us)

    // Analogous statistics for ancestor transactions
    uint64_t nCountWithAncestors;
    uint64_t nSizeWithAncestors;
    CAmount nModFeesWithAncestors;
    int64_t nSigOpCostWithAncestors;

    // ...
----

The advantage to having pre-computed data on descendants and ancestors stored with each transaction in the mempool is that operations involving adding and removing transactions can be performed faster.
When we add a transaction to the mempool we must update the descendant data for all ancestor ``CTxMemPoolEntry``'s.
Conversely if we remove a transaction from the mempool, we must also remove all of its descendants.
A particular area where speed can be critical is in block assembly.

Some of this extra transaction metadata however *does* count towards the mempool's maximum size, therefore a default mempool of 300MB will contain less than 300MB of serialised transactions.

== Adding transactions to the mempool

Transactions can be added to the mempool in four ways:

. Received in a `TX` network message

. From a transaction generated by the wallet or submitted through another interface like RPC.

. Loaded from mempool.dat

. From a disconnected block during a reorg


In all cases, the transaction is submitted to the mempool through AcceptToMemoryPool (ATMP).
For a transaction received over the P2P protocol, the call to ATMP is found in _net_processing.cpp_:

.net_processing.cpp
[source, cpp]
----
    // ...

    if (msg_type == NetMsgType::TX) {

    // ...

        const MempoolAcceptResult result = AcceptToMemoryPool(m_chainman.ActiveChainstate(), m_mempool, ptx, false /* bypass_limits */);
        const TxValidationState& state = result.m_state;

        if (result.m_result_type == MempoolAcceptResult::ResultType::VALID) {
            m_mempool.check(m_chainman.ActiveChainstate());
            // As this version of the transaction was acceptable, we can forget about any
            // requests for it.
            m_txrequest.ForgetTxHash(tx.GetHash());
            m_txrequest.ForgetTxHash(tx.GetWitnessHash());
            RelayTransaction(tx.GetHash(), tx.GetWitnessHash());
            m_orphanage.AddChildrenToWorkSet(tx, peer->m_orphan_work_set);

            pfrom.nLastTXTime = GetTime();

            LogPrint(BCLog::MEMPOOL, "AcceptToMemoryPool: peer=%d: accepted %s (poolsz %u txn, %u kB)\n",
                pfrom.GetId(),
                tx.GetHash().ToString(),
                m_mempool.size(), m_mempool.DynamicMemoryUsage() / 1000);

            for (const CTransactionRef& removedTx : result.m_replaced_transactions.value()) {
                AddToCompactExtraTransactions(removedTx);
            }

            // Recursively process any orphan transactions that depended on this one
            ProcessOrphanTx(peer->m_orphan_work_set);
        }

        // ...

----

...whereas for locally-generated transactions the call to ATMP comes from
`node/transaction.cpp::BroadcastTransaction()`, which is called from the `sendrawtransaction` RPC
and from various wallet functions.
We can see this in the call-graph for `AcceptToMemoryPool`:

image::validation_8h_af6c5c758554417ece7c885200c9a6d03_icgraph.svg[]

NOTE: `while` in the diagram stems from the `ThreadMessageHandler()` loop.

== AcceptToMemoryPool

The `AcceptToMemoryPool()` function accepts a new transaction into the mempool.

In the body of the function we can see the call to `MempoolAccept().AcceptSingleTransaction()` which is where the brunt of transaction validation occurs.
If this validation is successful, the "coin" will be added to the mempool:

.validation.cpp#AcceptToMemoryPoolWithTime()
[source,cpp]
----
{
    std::vector<COutPoint> coins_to_uncache;
    MemPoolAccept::ATMPArgs args { chainparams, nAcceptTime, bypass_limits, coins_to_uncache, test_accept };

    assert(std::addressof(::ChainstateActive()) == std::addressof(active_chainstate));
    const MempoolAcceptResult result = MemPoolAccept(pool, active_chainstate).AcceptSingleTransaction(tx, args);
    if (result.m_result_type != MempoolAcceptResult::ResultType::VALID) {
        // Remove coins that were not present in the coins cache before calling
        // AcceptSingleTransaction(); this is to prevent memory DoS in case we receive a large
        // number of invalid transactions that attempt to overrun the in-memory coins cache
        // (`CCoinsViewCache::cacheCoins`).

        for (const COutPoint& hashTx : coins_to_uncache)
            active_chainstate.CoinsTip().Uncache(hashTx);
    }
    // After we've (potentially) uncached entries, ensure our coins cache is still within its size limits
    BlockValidationState state_dummy;
    active_chainstate.FlushStateToDisk(chainparams, state_dummy, FlushStateMode::PERIODIC);
    return result;
}
----

More information on this function can be found in <<AcceptSingleTransaction>>.

=== Package relay

Since the commit this documentation is based on, the concept of "package relay" has been introduced to Bitcoin Core.
glozow describes the rationale behind the package relay proposal in her gist https://gist.github.com/glozow/dc4e9d5c5b14ade7cdfac40f43adb18a[Package mempool accept].

This began with a refactoring which saw the following lines into the `MempoolAccept::AcceptSingleTransaction()` function we looked at above:

.valiation.cpp#MempoolAccept::AcceptSingleTransaction()
[source,cpp]
----
    if (m_rbf && !ReplacementChecks(ws)) return MempoolAcceptResult::Failure(ws.m_state);
----

The refactoring was done in commit https://github.com/bitcoin/bitcoin/commit/c9b1439ca9ab691f4672d2cbf33d9381f2985466[c9b1439] as part of https://github.com/bitcoin/bitcoin/pull/23381[PR#23381].
Following this https://github.com/bitcoin/bitcoin/pull/22674[PR#22674] introduced single child packages into the mempool acceptance flow.

The document https://github.com/bitcoin/bitcoin/blob/master/doc/policy/packages.md[doc/policy/packages.md] contains current information on the stated package acceptance rules.

